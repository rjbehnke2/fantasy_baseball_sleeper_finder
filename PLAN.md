# Fantasy Baseball Sleeper Finder — Implementation Plan

## Vision

A web application that uses ML models and LLM-powered analysis trained on baseball statistics and advanced analytics to generate AI-derived player evaluations for **dynasty auction** fantasy baseball leagues. The core differentiator is AI-powered insights: sleeper identification, bust detection, regression prediction, consistency scoring, composite value rankings, and **narrative scouting reports generated by an LLM** that synthesize all analytical signals into human-quality write-ups — the kind of analysis you'd get from a dedicated league analyst.

**Dynasty focus** means long-term value, age curves, prospect trajectories, and multi-year outlook matter as much or more than next-season projections. **Auction focus** means every player has a dollar value, and the key question is surplus value — the gap between what a player is worth and what they'll cost you.

---

## 1. Tech Stack

| Layer | Technology | Rationale |
|---|---|---|
| **Backend** | Python 3.11+ / FastAPI / Uvicorn | ML models are Python-native; FastAPI gives auto-docs, async, Pydantic validation |
| **Frontend** | Next.js (App Router) + shadcn/ui + Tailwind CSS + Recharts | Server-side rendering, production-quality components, built-in charting |
| **ML** | scikit-learn + XGBoost + LightGBM + SHAP | XGBoost/LightGBM excel on tabular baseball data; SHAP provides explainability |
| **AI/LLM** | Anthropic Python SDK (Claude API) | Powers narrative scouting reports — the primary AI differentiator |
| **Database** | PostgreSQL (SQLAlchemy 2.0 + Alembic) | Handles millions of Statcast rows, JSONB for flexible schemas, concurrent access |
| **Data** | pybaseball + MLB-StatsAPI | pybaseball aggregates FanGraphs/Savant/Lahman; MLB-StatsAPI for rosters/injuries |
| **Scheduling** | APScheduler | Nightly data refresh without the complexity of Celery |
| **Package Mgmt** | uv | Fast, reliable Python dependency management |
| **Infra** | Docker Compose (dev), GitHub Actions (CI/CD) | Single-command local stack, automated deploys |

---

## 2. Project Structure

```
fantasy_baseball_sleeper_finder/
├── README.md
├── PLAN.md
├── pyproject.toml
├── docker-compose.yml
├── .env.example
├── .gitignore
│
├── backend/
│   ├── alembic/                      # Database migrations
│   │   ├── versions/
│   │   ├── env.py
│   │   └── alembic.ini
│   │
│   ├── app/
│   │   ├── __init__.py
│   │   ├── main.py                   # FastAPI app factory, lifespan events
│   │   ├── config.py                 # Pydantic BaseSettings
│   │   ├── dependencies.py
│   │   │
│   │   ├── api/v1/
│   │   │   ├── router.py             # Aggregates all v1 routers
│   │   │   ├── players.py            # Player lookup, search, detail
│   │   │   ├── rankings.py           # AI rankings endpoints
│   │   │   ├── comparisons.py        # Player comparison endpoints
│   │   │   ├── insights.py           # Sleepers, busts, regression
│   │   │   └── league.py             # League settings customization
│   │   │
│   │   ├── models/                   # SQLAlchemy ORM models
│   │   │   ├── player.py
│   │   │   ├── batting_stats.py
│   │   │   ├── pitching_stats.py
│   │   │   ├── statcast.py
│   │   │   ├── projections.py
│   │   │   ├── scouting_report.py    # Cached LLM-generated reports
│   │   │   └── league_settings.py
│   │   │
│   │   ├── schemas/                  # Pydantic request/response schemas
│   │   │   ├── player.py
│   │   │   ├── rankings.py
│   │   │   ├── insights.py
│   │   │   ├── scouting_report.py
│   │   │   └── league.py
│   │   │
│   │   ├── services/                 # Business logic layer
│   │   │   ├── player_service.py
│   │   │   ├── ranking_service.py
│   │   │   ├── insight_service.py
│   │   │   ├── scouting_report_service.py  # LLM scouting report generation
│   │   │   └── auction_service.py          # Auction dollar values & surplus calc
│   │   │
│   │   └── db/
│   │       ├── session.py            # Async SQLAlchemy session factory
│   │       └── base.py               # Declarative base
│   │
│   ├── data_pipeline/
│   │   ├── fetchers/
│   │   │   ├── fangraphs_fetcher.py  # pybaseball batting_stats/pitching_stats
│   │   │   ├── statcast_fetcher.py   # pybaseball statcast functions
│   │   │   ├── roster_fetcher.py     # MLB-StatsAPI roster/injury data
│   │   │   └── player_id_mapper.py   # Cross-reference player IDs
│   │   │
│   │   ├── transformers/
│   │   │   ├── cleaning.py           # Data cleaning, null handling
│   │   │   ├── feature_engineering.py # Derived features (differentials, trends)
│   │   │   └── aggregations.py       # Pitch-level to season-level rollups
│   │   │
│   │   ├── loaders/
│   │   │   └── db_loader.py          # Write cleaned data to PostgreSQL
│   │   │
│   │   ├── orchestrator.py           # Pipeline scheduling logic
│   │   └── backfill.py               # One-time historical data load
│   │
│   ├── ml/
│   │   ├── features/
│   │   │   ├── feature_store.py      # Central feature definitions
│   │   │   ├── batter_features.py
│   │   │   └── pitcher_features.py
│   │   │
│   │   ├── models/
│   │   │   ├── marcel_baseline.py    # Marcel projection (baseline to beat)
│   │   │   ├── sleeper_model.py      # Sleeper detection
│   │   │   ├── bust_model.py         # Bust detection
│   │   │   ├── regression_model.py   # Regression direction prediction
│   │   │   ├── consistency_model.py  # Multi-year sticky-stat consistency scorer
│   │   │   ├── improvement_model.py  # Skills-stat trajectory scorer
│   │   │   ├── value_model.py        # Composite AI Value Score
│   │   │   └── trajectory_model.py   # TFT career trajectory (Phase 3)
│   │   │
│   │   ├── training/
│   │   │   ├── train_pipeline.py     # End-to-end training orchestration
│   │   │   ├── evaluation.py         # Backtesting, cross-validation
│   │   │   └── hyperparameter.py     # Optuna hyperparameter search
│   │   │
│   │   ├── inference/
│   │   │   ├── predictor.py          # Load models, generate predictions
│   │   │   └── explainer.py          # SHAP explanations
│   │   │
│   │   └── artifacts/                # Serialized models (.joblib, .xgb)
│   │       └── .gitkeep
│   │
│   ├── llm/
│   │   ├── __init__.py
│   │   ├── client.py                 # Anthropic SDK client wrapper
│   │   ├── prompts/
│   │   │   ├── scouting_report.py    # Prompt templates for scouting reports
│   │   │   ├── report_sections.py    # Sub-prompts: dynasty outlook, auction value, etc.
│   │   │   └── formatters.py         # Stat context formatters (structured → prompt-ready)
│   │   ├── generators/
│   │   │   ├── scouting_generator.py # Orchestrates full report generation
│   │   │   └── cache_manager.py      # Report caching / invalidation logic
│   │   └── tests/
│   │       └── test_scouting.py
│   │
│   └── tests/
│       ├── conftest.py
│       ├── test_api/
│       ├── test_pipeline/
│       └── test_ml/
│
├── frontend/
│   ├── package.json
│   ├── next.config.ts
│   ├── tailwind.config.ts
│   ├── tsconfig.json
│   │
│   └── src/
│       ├── app/
│       │   ├── layout.tsx            # Root layout with sidebar nav
│       │   ├── page.tsx              # Dashboard
│       │   ├── players/
│       │   │   ├── page.tsx          # Player rankings table
│       │   │   └── [playerId]/
│       │   │       └── page.tsx      # Player detail
│       │   ├── sleepers/page.tsx     # Sleeper picks
│       │   ├── busts/page.tsx        # Bust alerts
│       │   ├── compare/page.tsx      # Side-by-side comparison
│       │   └── settings/page.tsx     # League settings
│       │
│       ├── components/
│       │   ├── ui/                   # shadcn/ui components
│       │   ├── players/
│       │   │   ├── player-card.tsx
│       │   │   ├── player-table.tsx
│       │   │   ├── player-radar.tsx
│       │   │   └── scouting-report.tsx  # LLM scouting report display
│       │   ├── insights/
│       │   │   ├── sleeper-card.tsx
│       │   │   ├── bust-alert.tsx
│       │   │   └── regression-indicator.tsx
│       │   ├── auction/
│       │   │   ├── auction-value-badge.tsx  # Dollar value display
│       │   │   └── surplus-indicator.tsx    # Surplus value vs. cost
│       │   └── charts/
│       │       ├── stat-trend.tsx
│       │       ├── value-gauge.tsx
│       │       ├── consistency-heatmap.tsx
│       │       └── dynasty-trajectory.tsx   # Multi-year value projection
│       │
│       ├── lib/
│       │   ├── api.ts                # API client
│       │   ├── types.ts
│       │   └── utils.ts
│       │
│       └── hooks/
│           ├── use-players.ts
│           ├── use-rankings.ts
│           └── use-league-settings.ts
│
├── notebooks/
│   ├── 01_data_exploration.ipynb
│   ├── 02_feature_engineering.ipynb
│   ├── 03_model_prototyping.ipynb
│   └── 04_model_evaluation.ipynb
│
└── scripts/
    ├── seed_database.py
    ├── train_models.py
    └── generate_projections.py
```

---

## 3. Data Pipeline

### 3.1 Data Sources

| Source | Library | Data Type | Historical Depth |
|---|---|---|---|
| FanGraphs | `pybaseball.batting_stats()` / `pitching_stats()` | Season-level advanced stats (wOBA, xwOBA, wRC+, SIERA, FIP, Barrel%, etc.) | 2015-present |
| Baseball Savant | `pybaseball.statcast()` | Pitch-level Statcast (EV, LA, spin rate, etc.) | 2019-present |
| Lahman Database | `pybaseball` Lahman module | Historical season stats | 1871-present |
| MLB Stats API | `MLB-StatsAPI` | Rosters, injuries, schedules | Current |

### 3.2 Fetching Strategy

**Historical Backfill** (one-time, via `scripts/seed_database.py`):
- FanGraphs batting/pitching stats: 2015-present (single call per stat type)
- Statcast aggregates: 2019-present, fetched in 7-day chunks to stay under Baseball Savant's 30K row limit
- Always enable `pybaseball.cache.enable()` before fetching

**Nightly Incremental Updates** (via APScheduler, 5:00 AM ET):
- Yesterday's Statcast data
- Re-aggregate current-season per-player Statcast summaries
- Roster changes and injury updates via MLB-StatsAPI
- Monthly full FanGraphs stats refresh

### 3.3 Player ID Mapping

Critical integration challenge. pybaseball uses MLBAM IDs, FanGraphs has its own IDs, Baseball Reference uses another. The `player_id_mapper.py` module uses `pybaseball.playerid_reverse_lookup()` to build a canonical player table with all three ID systems for reliable cross-source joins.

### 3.4 Database Schema

**`players`** — canonical player record
- `id` (PK), `mlbam_id`, `fangraphs_id`, `bbref_id`, `full_name`, `position`, `team`, `birth_date`, `mlb_debut_date`, `status`, `prospect_rank` (historical top-100 ranking, if any), `mlb_service_time`

**`batting_seasons`** — one row per player per season
- `player_id` (FK), `season`, `pa`, `ab`, `h`, `hr`, `rbi`, `sb`, `avg`, `obp`, `slg`, `woba`, `xwoba`, `wrc_plus`, `barrel_pct`, `hard_hit_pct`, `sprint_speed`, `babip`, `k_pct`, `bb_pct`, `war`, `adp`

**`pitching_seasons`** — one row per player per season
- `player_id` (FK), `season`, `ip`, `era`, `whip`, `fip`, `xfip`, `siera`, `k_pct`, `bb_pct`, `k_bb_pct`, `csw_pct`, `swstr_pct`, `barrel_pct_against`, `hard_hit_pct_against`, `stuff_plus`, `war`, `babip`, `lob_pct`, `hr_fb_pct`, `adp`

**`statcast_aggregates`** — per-player-per-season Statcast summaries
- `player_id` (FK), `season`, `avg_exit_velocity`, `max_exit_velocity`, `avg_launch_angle`, `barrel_pct`, `sweet_spot_pct`, `avg_spin_rate`, `xba`, `xslg`, `xwoba`, `xera`

**`monthly_splits`** — per-player-per-month (for consistency scoring)
- `player_id` (FK), `season`, `month`, key rate stats

**`projections`** — model outputs
- `player_id` (FK), `run_date`, `model_version`, `sleeper_score`, `bust_score`, `regression_direction`, `regression_magnitude`, `consistency_score`, `improvement_score`, `ai_value_score`, `confidence`, `shap_explanations` (JSONB), `stat_consistency_breakdown` (JSONB — per-stat CV values), `stat_improvement_breakdown` (JSONB — per-stat trend slopes and r² values), `auction_value` (projected dollar value), `dynasty_value` (long-term value score 0-100), `surplus_value` (auction_value minus expected cost)

**`scouting_reports`** — cached LLM-generated reports
- `id` (PK), `player_id` (FK), `report_type` (full/sleeper_spotlight/bust_warning/dynasty_outlook), `content` (TEXT — the full generated report), `model_scores_snapshot` (JSONB — scores at time of generation), `llm_model_version`, `generated_at`, `stale` (boolean — flagged when underlying data changes significantly)

**`league_settings`** — user-customizable league configs
- `id`, `name`, `scoring_type` (roto/h2h_categories/h2h_points), `league_format` (redraft/keeper/dynasty), `roster_slots` (JSONB), `stat_categories` (JSONB), `auction_budget` (default 260), `roster_size`, `keeper_rules` (JSONB — max keepers, cost inflation, etc.)

### 3.5 Feature Engineering

This is the intellectual core of the pipeline — the quality of features determines the quality of all ML models.

**Differential Features (actual vs. expected):**
- `woba_minus_xwoba`: positive = overperforming (bust signal), negative = underperforming (sleeper signal)
- `ba_minus_xba`, `era_minus_xera`: same principle
- `babip_minus_league_avg`: high delta suggests regression

**Trend Features (year-over-year):**
- `barrel_pct_yoy_delta`, `k_pct_yoy_delta`, `bb_pct_yoy_delta`, `csw_pct_yoy_delta`
- 2-year and 3-year trend slopes via linear regression on seasonal values

**Age Curve Features:**
- `age`, `years_from_peak` (peak ~27 hitters, ~26 pitchers)
- `age_bucket`: pre-peak / peak / early-decline / late-decline
- `post_hype_flag`: age 26-29, former top prospect, MLB underperformer

**Consistency Features (multi-year, weighted by stat stickiness):**

Consistency is measured across seasons (not months within a season). Stats are weighted by their year-over-year correlation — sticky stats that a player repeats reliably are worth more than volatile stats that fluctuate with luck.

*Sticky stat tiers for weighting:*
| Tier | Hitter Stats (YoY r) | Pitcher Stats (YoY r) |
|---|---|---|
| Tier 1 (highest weight) | K% (.84), BB% (.76), ISO (.76) | K% (.75), K-BB% (.70+), SwStr% (high) |
| Tier 2 | Barrel% (.80), EV (.82), Hard Hit% (.78), GB/FB% (.72-.78) | CSW% (high), GB% (.78), FIP/SIERA |
| Tier 3 (lowest weight) | wOBA, wRC+, Sprint Speed | xERA, Stuff+ |
| Excluded (too volatile) | BABIP (.37), AVG, LD% (.22) | ERA (.38), BABIP, LOB% |

*Per-stat consistency calculation:*
For each sticky stat, compute the coefficient of variation (CV) across the player's last 3 seasons:
```
stat_cv = std_dev(stat_year1, stat_year2, stat_year3) / mean(stat_year1, stat_year2, stat_year3)
```
A low CV = consistent. Weight each stat's CV by its stickiness tier, then combine:
```
weighted_consistency = sum(tier_weight_i * (1 - normalized_cv_i)) / sum(tier_weight_i)
```
Scale to 0-100 where 100 = rock-solid across years in sticky stats. Requires minimum 2 seasons of data (3 preferred).

**Improvement Features (multi-year skills-stat trends):**

Track directional trends in skills stats across 2-3 seasons. Only sticky/skills stats are tracked — improvement in volatile stats is ignored as likely noise.

*Hitter skills stats tracked:* K%, BB%, Barrel%, Hard Hit%, EV, Sprint Speed
*Pitcher skills stats tracked:* K%, BB%, K-BB%, SwStr%, CSW%, GB%

*Per-stat trend calculation:*
```
trend_slope = linear_regression_slope(stat over last 3 seasons)
trend_r² = how well the trend fits (high r² = steady improvement, low = noisy)
trend_signal = trend_slope * trend_r²  # slope discounted by fit quality
```
Aggregate across all tracked stats, weighted by stickiness tier.

*Age-adjusted improvement weighting:*
```
age_multiplier:
  age < 27:  1.2  (improvement aligns with natural development — more likely real)
  age 27-30: 1.0  (neutral)
  age 30-33: 0.6  (improvement against aging curve — treat skeptically)
  age > 33:  0.3  (improvement at this age is almost always noise)
```

**Context Features:**
- `team_park_factor`, `lineup_position_avg`, `playing_time_trend`

**Marcel Baseline Features:**
- Weighted 3-year average (5/4/3 weighting)
- Regression to mean (1200 PA batters / 134 outs pitchers of league-average blended in)
- Age adjustment: +/- 0.006 per year from peak

---

## 4. ML Models (Core Differentiator)

### 4.0 Marcel Baseline — The Bar to Clear

Every ML model must demonstrably outperform the Marcel system. Marcel is implemented first and its projections also serve as input features for downstream models.

**Formula:** `projected_stat = (5 * year_N + 4 * year_N-1 + 3 * year_N-2) / 12`, regressed toward league mean proportional to playing time, age-adjusted.

### 4.1 Sleeper Finder Model

**Objective:** Identify players whose underlying quality (Statcast, expected stats) significantly exceeds their surface stats or auction cost. In dynasty context, also flags young players whose long-term trajectory is underpriced.

**Training Target:** Binary classification. A "sleeper" = player whose auction cost was in the bottom 60% of rostered players but who finished the season in the top 40% by fantasy value.

**Key Features (expected importance order):**
1. `xwoba_minus_woba` (negative = quality exceeds results)
2. `barrel_pct` + `barrel_pct_yoy_delta`
3. `hard_hit_pct` + `hard_hit_pct_yoy_delta`
4. `k_pct_yoy_delta` (declining K rate)
5. `csw_pct_yoy_delta` (pitchers: improving stuff)
6. `age_bucket` (pre-peak more likely to break out)
7. `playing_time_trend` (increasing = team trust)
8. `post_hype_flag`
9. Marcel delta (projected vs. actual)
10. `auction_cost_pct` (cheap + good underlying = sleeper)
11. `years_of_control` (dynasty: more team control = more long-term value)

**Architecture:** LightGBM + XGBoost ensemble with class-weight balancing (sleepers are ~5-10% of pool). Calibrated probabilities via `CalibratedClassifierCV`. Hyperparameter tuning with Optuna, 5-fold time-series CV.

**Output:** `sleeper_score` (0-100) + SHAP top-3 feature explanations per player.

### 4.2 Bust Detector Model

**Objective:** Flag players whose surface stats are propped up by unsustainable luck, making them likely to disappoint relative to their auction cost. In dynasty, also flags aging players whose decline is being underpriced.

**Training Target:** Binary classification. A "bust" = player whose auction cost was in the top 30% but who finished outside the top 60% by fantasy value (or 60+ days on IL).

**Key Features:**
1. `woba_minus_xwoba` (positive = stats exceed quality)
2. `babip_minus_league_avg` (high BABIP regresses)
3. `hr_fb_pct` vs. league average (unsustainable HR/FB)
4. `lob_pct` for pitchers (high LOB% regresses down)
5. `age_bucket` (late-decline = higher bust risk)
6. `injury_history_score` (weighted IL stints)
7. `era_minus_fip` for pitchers
8. `consistency_score` (volatile = higher bust risk)
9. `playing_time_trend` (declining = team losing faith)
10. `age_times_cost` (dynasty: expensive + old = highest bust risk)

**Architecture:** Same LightGBM + XGBoost ensemble. Same tuning framework.

**Output:** `bust_score` (0-100) + SHAP top-3 explanations.

### 4.3 Regression Direction Model

**Objective:** Predict whether a player will improve or decline, and by how much.

**Training Target:** Regression task. Target = `next_season_woba - current_season_woba` (batters) or `current_season_fip - next_season_fip` (pitchers, inverted for unified "improvement" metric).

**Key Features:** All differential features + Marcel deltas + YoY trends + age curve.

**Architecture:** XGBoost Regressor + LightGBM Regressor ensemble. Evaluated with MAE and directional accuracy.

**Output:** `regression_direction` (signed float), `regression_confidence` (from quantile regression prediction intervals).

### 4.4 Consistency Score (Multi-Year, Sticky-Stat Weighted)

**Not an ML model** — a statistical calculation measuring how repeatable a player's skills-based performance is across seasons.

**Why multi-year, not month-to-month:** Month-to-month variance within a season is dominated by small sample noise. A hitter can have a .180 April and a .340 May purely from BABIP variance. Multi-year consistency in *sticky* stats reveals whether a player has an established, reliable skill level — which is what dynasty managers need to trust.

**Why weight by stat stickiness:** A player who posts consistent K% and Barrel% over 3 years has a genuinely repeatable skill profile. A player who posts consistent AVG or BABIP over 3 years may just be consistently lucky. Weighting by year-over-year correlation ensures the score reflects real skill stability.

**Stat Stickiness Tiers:**
| Tier | Weight | Hitter Stats (YoY r) | Pitcher Stats (YoY r) |
|---|---|---|---|
| 1 (most sticky) | 1.0 | K% (.84), BB% (.76), ISO (.76) | K% (.75), K-BB% (.70+), SwStr% |
| 2 | 0.7 | Barrel% (.80), EV (.82), Hard Hit% (.78), GB/FB% (.75) | CSW%, GB% (.78), FIP, SIERA |
| 3 | 0.4 | wOBA, wRC+, Sprint Speed | xERA, Stuff+ |
| Excluded | 0.0 | BABIP (.37), AVG, LD% (.22) | ERA (.38), BABIP, LOB% |

**Calculation:**
1. For each sticky stat, compute the coefficient of variation (CV) across the player's last 3 seasons:
   ```
   stat_cv = std_dev(stat_y1, stat_y2, stat_y3) / mean(stat_y1, stat_y2, stat_y3)
   ```
2. Convert each CV to a per-stat consistency score: `stat_consistency = 1 - normalized_cv` (0 = wildly different each year, 1 = near-identical)
3. Compute the weighted average across all stats using tier weights:
   ```
   raw_consistency = sum(tier_weight_i * stat_consistency_i) / sum(tier_weight_i)
   ```
4. Scale to 0-100.

**Minimum data requirement:** 2 seasons (3 preferred). Players with only 1 season get no consistency score (displayed as "N/A — insufficient track record").

**What a high score means for dynasty:** A player with consistency 85+ has an established skill floor. You know what you're getting. In an auction, they're safer to pay up for. A player with consistency 40 is a volatile gamble — potentially useful if cheap, but risky at a premium auction price.

**Output:** `consistency_score` (0-100) + per-stat consistency breakdown (for the UI to show which skills are stable vs. volatile) + years of data used.

### 4.5 AI Value Score (Composite)

**Objective:** Single 0-100 number combining all model outputs with contextual factors, weighted for dynasty auction leagues.

**Formula:**
```
ai_value_score = (
    w1 * projected_fantasy_value +      # Marcel + regression adjustment
    w2 * sleeper_upside +               # sleeper_score * (1 - current_value_pct)
    w3 * (100 - bust_risk) +            # Inverse bust score
    w4 * consistency_score +
    w5 * age_curve_factor +             # Bonus pre-peak, penalty late-decline
    w6 * opportunity_score +            # Playing time / role security
    w7 * dynasty_premium +             # Long-term value (see below)
    w8 * improvement_score             # Skills trajectory (positive = improving, negative = declining)
)
```

**Dynasty Premium Calculation:**
The `dynasty_premium` adjusts the value score to reflect multi-year outlook, which is the defining feature of dynasty leagues:
```
dynasty_premium = (
    years_of_control_bonus +            # More years = more value
    age_trajectory_score +              # Pre-peak players get a premium
    prospect_pedigree_bonus +           # Former top prospects still developing
    positional_scarcity_factor          # Dynasty-thin positions worth more long-term
)
```
- A 24-year-old with 5 years of control and improving Statcast metrics gets a significant dynasty premium even if his current stats are modest
- A 33-year-old with elite current stats but declining velocity trends gets a dynasty penalty
- Post-hype sleepers (age 26-29, former top-100 prospect, hasn't broken out yet) get a targeted bonus — these are classic dynasty buy-low windows

Weights `w1-w8` calibrated via linear regression on historical seasons, with dynasty weights trained on multi-year value windows (3-year cumulative fantasy value, not just next season). The improvement_score component (w8) allows the model to boost players on upward trajectories and penalize those in decline — critical for dynasty where you're buying future seasons.

**League Customization:** `projected_fantasy_value` changes based on user's league settings (categories vs. points, roster composition, keeper/dynasty rules). Rankings adjust accordingly.

**Output:** `ai_value_score` (0-100) + component breakdown for the UI explainer.

### 4.6 AI Scouting Reports (LLM-Powered)

**Objective:** Generate narrative scouting reports that synthesize all analytical signals — model scores, Statcast data, trends, age context, dynasty outlook, auction implications — into human-quality write-ups. This is the primary AI differentiator of the application.

**Why this matters:** A sleeper score of 78 is a number. A scouting report that says *"Vazquez quietly overhauled his swing last spring, and the Statcast data backs it up — his barrel rate jumped from 6% to 11%, exit velocity climbed 3 mph, yet his BABIP sat at .260 all year. He was one of the unluckiest hitters in baseball. At $3 in your auction, he's a potential league-winner with 5 years of team control remaining."* — that's actionable intelligence.

**Architecture:**

The scouting report system has three layers:

**Layer 1: Context Assembly (`formatters.py`)**
For each player, assemble a structured context document containing:
- Biographical: name, age, team, position, years of control, prospect history
- Current season stats: all key metrics with league-average comparisons and percentile ranks
- 3-year trends: each stat's trajectory with direction arrows
- Model scores: sleeper_score, bust_score, regression_direction, consistency_score, improvement_score, ai_value_score — with the top SHAP features for each
- Skills trajectory: per-stat improvement trends (e.g., "K-BB% improved 10% → 14% → 18% over 3 seasons, r²=0.99") and per-stat consistency breakdown
- Differentials: xwOBA vs. wOBA, xBA vs. BA, xERA vs. ERA — the "luck gap"
- Dynasty context: age curve position, years until free agency, comparable players at this age
- Auction context: projected dollar value, expected cost, surplus value

This structured data is formatted into a prompt-ready document that provides the LLM with complete, grounded context. The LLM never invents stats — it synthesizes and narrates what the models found.

**Layer 2: Prompt Templates (`scouting_report.py`, `report_sections.py`)**
A system prompt establishes the LLM's role as a fantasy baseball analyst with dynasty/auction expertise. The prompt includes:
- Explicit instruction to only reference stats and scores provided in the context (no hallucination)
- Tone guidance: authoritative but accessible, like a trusted league-mate who's done the homework
- Section structure for the report (see below)
- Dynasty-specific framing: always consider long-term value, age trajectory, and cost basis

**Report Sections:**
1. **Headline Assessment** (1-2 sentences): The takeaway. "Buy" / "Sell" / "Hold" with conviction level.
2. **The Case For** (1 paragraph): What the underlying data says in the player's favor — Statcast quality, improving trends, favorable age. Written as a narrative, not a stat dump.
3. **The Case Against** (1 paragraph): Risk factors — regression signals, injury history, declining trends, age concerns.
4. **Dynasty Outlook** (1 paragraph): Multi-year trajectory. Where is this player on his career arc? What's the 3-year projection? Is he a buy-and-hold cornerstone or a sell-high candidate?
5. **Auction Verdict** (1-2 sentences): Specific dollar value recommendation. "Worth up to $22 in a 12-team dynasty auction — $5 more than his expected cost, making him one of the best surplus values on the board."

**Layer 3: Generation & Caching (`scouting_generator.py`, `cache_manager.py`)**

- **Batch generation:** After each model inference run, generate reports for the top ~300 relevant players (top 250 by value + top 50 sleepers/busts). Reports are generated in batch via async Claude API calls. This avoids per-request latency — users get instant access to pre-generated reports.
- **On-demand generation:** If a user views a player without a cached report, generate one on-the-fly (takes ~3-5 seconds). Show a loading state in the UI.
- **Cache invalidation:** Reports are marked `stale` when any of these triggers occur:
  - Model scores change by more than 10 points
  - Player changes teams (trade/free agency)
  - Player goes on/off the IL
  - New season data significantly shifts their stats
  - A new model version is deployed
- **Staleness regeneration:** Stale reports are regenerated in the next nightly batch. Until regenerated, the old report is still served (better than nothing) with a "Report may be outdated" indicator.
- **Cost control:** Claude API calls are the main operational cost. Batch generation of ~300 reports per cycle is manageable. On-demand generation is throttled (max 10 concurrent requests). Reports are cached aggressively — most users will hit the cache.

**Report Types:**
| Type | When Generated | Content Focus |
|---|---|---|
| `full` | Batch (top 300 players) | Complete 5-section report |
| `sleeper_spotlight` | Batch (top 50 by sleeper_score) | Emphasizes undervaluation case + dynasty buy-low window |
| `bust_warning` | Batch (top 50 by bust_score) | Emphasizes risk factors + sell-high case |
| `dynasty_outlook` | Batch (top prospects + young players) | Emphasizes career trajectory + long-term value |

**Quality Guardrails:**
- The LLM is never asked to generate stats — only to narrate stats provided in the context
- Each report includes a `model_scores_snapshot` stored alongside it, so the UI can show if the report's basis has shifted
- Reports include a "Generated on [date] using [model version]" footer for transparency

### 4.7 Auction Valuation Engine

**Objective:** Convert projected fantasy production into dollar values for auction drafts, and calculate surplus value (the gap between what a player is worth and what they'll cost).

**Methodology:**

**Step 1: Stat Projections → Fantasy Points**
Convert each player's projected stats (from Marcel + regression adjustment) into fantasy points or category contributions based on the user's league settings.

**Step 2: Fantasy Points → Dollar Values (Standings Gain Points method)**
The standard auction valuation approach:
1. For each stat category, calculate how much one additional unit of that stat would improve your standings (the "SGP" — standings gain point)
2. A player's total value = sum of SGP contributions across all categories
3. Scale to the league's auction budget: `dollar_value = (player_sgp / total_pool_sgp) * total_league_dollars_on_hitters_or_pitchers`

For points leagues, the conversion is simpler: projected points → dollar value proportional to budget.

**Step 3: Surplus Value**
```
surplus_value = projected_dollar_value - expected_auction_cost
```
`expected_auction_cost` is derived from ADP-to-dollar mappings, historical auction results, or user-provided keeper costs.

**Dynasty Adjustments:**
- **Multi-year dollar value:** In dynasty, a player's value isn't just their next-season projection — it's the sum of projected value over their remaining years of control, discounted by uncertainty. A $20/year player with 5 years of control is worth more than a $25/year player with 1 year left.
- **Keeper cost inflation:** If the league inflates keeper costs by $5/year, the model accounts for when a player's keeper cost will exceed their projected value (the "keep/cut" inflection point).
- **Aging discount rate:** Future seasons are discounted more heavily for older players (higher probability of decline/injury).

**Output:** `auction_value` (dollar amount), `dynasty_value` (0-100 long-term score), `surplus_value` (dollar amount), `keep_cut_horizon` (years until keeper cost exceeds value).

### 4.8 Improvement Score (Skills-Stat Trajectory)

**Objective:** Quantify whether a player is on a genuine developmental trajectory by measuring consistent year-over-year improvement in skills stats. Distinct from the Regression model (which looks at actual-vs-expected gaps for a single season), the Improvement Score looks at multi-year directional trends in the stats most likely to reflect real skill changes.

**Not an ML model** — a statistical calculation from multi-year skills-stat trends, with age-based weighting informed by developmental curve research.

**Why this matters for dynasty:** In a dynasty league, you're not just buying current production — you're buying a trajectory. A 24-year-old pitcher whose K-BB% has improved from 10% → 14% → 18% over three seasons is on a developmental curve that suggests further gains (or at minimum, sustainment). That trajectory is worth paying for, even if his current ERA doesn't reflect it yet. Conversely, a 32-year-old whose K% is declining year-over-year is on a trajectory that auction price hasn't caught up to yet.

**Research basis:**
- K% and BB% are "the most predictive statistics by a considerable margin" (Nate Silver / PECOTA)
- Players naturally improve until ~27, with biggest gains before 25. Improvement that aligns with the aging curve is more trustworthy.
- Gradual multi-year improvement (high trend r²) is more sustainable than a single-year spike (low trend r²)
- Skills stats (K%, BB%, Barrel%, EV) improvements backed by mechanical/approach changes tend to stick; outcome stat (AVG, ERA, BABIP) improvements tend to regress

**Skills Stats Tracked:**

| Hitters | Pitchers |
|---|---|
| K% (lower = better) | K% (higher = better) |
| BB% (higher = better) | BB% (lower = better) |
| Barrel% | K-BB% |
| Hard Hit% | SwStr% |
| Avg Exit Velocity | CSW% |
| Sprint Speed | GB% (context-dependent) |

**Calculation:**
1. For each skills stat, fit a linear regression across 3 seasons (minimum 2):
   ```
   trend_slope = slope of (stat_y1, stat_y2, stat_y3)
   trend_r² = goodness of fit (1.0 = perfectly linear improvement, 0.0 = no trend)
   ```
2. Compute a per-stat improvement signal, discounting noisy trends:
   ```
   stat_improvement = normalize(trend_slope) * trend_r²
   ```
   A strong slope with poor fit (one-year spike then reversion) gets discounted. A moderate slope with excellent fit (steady gains) gets full credit.
3. Weight each stat by its stickiness tier (same tiers as Consistency Score).
4. Apply age multiplier:
   ```
   age < 27:  × 1.2  (aligns with natural development — high trust)
   age 27-30: × 1.0  (neutral)
   age 30-33: × 0.6  (against aging curve — skeptical)
   age > 33:  × 0.3  (almost certainly noise)
   ```
5. Aggregate and scale to 0-100. Score can also be negative (consistent decline), scaled to -100 to 0 for declining players.

**Score interpretation:**
| Range | Meaning |
|---|---|
| 70-100 | Strong, sustained skills improvement — likely real development |
| 40-69 | Moderate improvement trend — promising but watch for regression |
| 10-39 | Mild improvement or mixed signals |
| -10 to 10 | Flat / no meaningful trend |
| -10 to -39 | Mild decline in skills |
| -40 to -100 | Significant skills erosion — sell candidate in dynasty |

**Interaction with other models:**
- High improvement_score + high sleeper_score = strongest buy signal (improving AND undervalued)
- High improvement_score + low consistency_score = "volatile improver" — the improvement is real but the player hasn't stabilized yet (higher-risk, higher-reward)
- Negative improvement_score + high bust_score = strongest sell signal (declining AND overvalued)
- The improvement_score feeds into the AI Value Score as an additional component and is referenced in LLM scouting reports

**Output:** `improvement_score` (-100 to 100) + per-stat trend breakdown (slope, r², direction for each skills stat) + age multiplier applied.

---

## 5. API Design

### Base URL: `/api/v1`

### Players
| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/players` | Paginated search/list with filters (position, team, sort_by any score, sort_by auction_value/dynasty_value/surplus_value) |
| `GET` | `/players/{player_id}` | Full detail: bio, 3-year stats, all model scores, SHAP explanations, monthly splits, auction value, dynasty outlook |
| `GET` | `/players/{player_id}/stats` | Historical stats by season and stat type |
| `GET` | `/players/{player_id}/scouting-report` | LLM-generated scouting report (returns cached if available, generates on-demand if not; includes report_type param: full/sleeper_spotlight/bust_warning/dynasty_outlook) |

### Rankings
| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/rankings` | AI-powered rankings with value breakdown per player |
| `GET` | `/rankings/sleepers` | Top sleeper candidates with reasons |
| `GET` | `/rankings/busts` | Top bust risks with reasons |
| `GET` | `/rankings/regression` | Regression candidates by direction |
| `GET` | `/rankings/dynasty` | Dynasty-specific rankings (weighted toward long-term value, age, trajectory) |
| `GET` | `/rankings/auction-values` | All players sorted by projected auction dollar value, with surplus values |

### Comparisons
| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/compare?player_ids=1,2,3` | Side-by-side comparison with percentile-coded stats, auction values, dynasty outlook |

### League Settings
| Method | Endpoint | Description |
|---|---|---|
| `POST` | `/league-settings` | Create league config (scoring type, categories, roster, league_format: dynasty/keeper/redraft, auction_budget, keeper_rules) |
| `GET` | `/league-settings/{id}` | Retrieve league config |

### Insights & Metadata
| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/insights/daily` | Daily AI digest: risers, fallers, injury impacts |
| `GET` | `/model/info` | Model version, last-trained date, backtest accuracy |

---

## 6. Frontend Design

### Pages

**Dashboard (`/`)** — Landing page with:
- "Today's Top Sleepers" card (top 5 with one-line AI scouting summary each)
- "Bust Alerts" card (top 5 warnings with one-line risk summary)
- "Best Auction Values" card (top 5 by surplus value, showing projected $ vs. expected cost)
- "Dynasty Risers" card (players whose dynasty value increased most)
- Quick-search bar, model freshness indicator

**Player Rankings (`/players`)** — Full-width sortable/filterable table (Tanstack Table):
- Columns: Rank, Name, Team, Pos, Age, AI Value Score, Auction $, Surplus $, Dynasty Value, Sleeper Score, Bust Score, Consistency, Improvement, key stats
- Sidebar filters: position, team, age range, min PA/IP
- Toggle: All / Batters / Pitchers
- View presets: "Dynasty Rankings" / "Auction Values" / "Sleeper Board" / "Bust Watch"
- League settings toggle for personalized rankings

**Player Detail (`/players/[playerId]`)** — Most information-dense page:
- **AI Scouting Report** (prominent, top of page): The full LLM-generated narrative — headline assessment, case for, case against, dynasty outlook, auction verdict. Displayed in a styled card with a "Generated by AI" badge and timestamp. If not yet generated, show loading state with "Generating scouting report..."
- AI Assessment Card: value gauge (0-100, color gradient), sleeper/bust/consistency badges
- **Auction & Dynasty Card**: projected dollar value (large), surplus value, dynasty value score, keep/cut horizon ("Worth keeping for 3 more years at current inflation")
- Stat Trends: 3-year line charts (wOBA, xwOBA, Barrel%, K%)
- Dynasty Trajectory Chart: projected multi-year value curve with confidence band
- Monthly Splits Heatmap
- Radar Chart: percentile ranks across key metrics (Power, Contact, Speed, Discipline)
- "Compare with..." shortcut

**Sleepers (`/sleepers`)** — Card layout:
- Sleeper score (large), projected auction $ and surplus value
- AI scouting summary (2-3 sentence excerpt from the sleeper_spotlight report)
- Mini sparkline: xwOBA vs. wOBA over 3 seasons
- Sortable, position-filterable

**Busts (`/busts`)** — Same card layout, warning color scheme (amber/red):
- Bust score, current auction cost, projected value loss
- AI scouting summary (excerpt from bust_warning report)
- Key risk factors as visual indicators

**Compare (`/compare`)** — Select 2-5 players:
- Side-by-side stat table, cells color-coded by percentile
- Auction value comparison row ($ values, surplus)
- Dynasty value comparison with trajectory overlay
- Overlaid trend line charts
- Radar chart overlay

**Settings (`/settings`)** — League configuration form:
- League format: dynasty / keeper / redraft
- Scoring type (roto/H2H categories/H2H points)
- Stat categories (checkboxes)
- Roster slots, points-per-stat values
- Auction budget (default $260)
- Keeper/dynasty rules: max keepers, cost inflation rate, contract lengths

### Design Principles
1. **Lead with the scouting report**: The AI narrative is the hero content — it's what makes this app different from every stats dashboard
2. **Dollar signs everywhere**: In an auction league, every player has a price. Show auction $ and surplus $ on every card, every table row, every comparison
3. **Dynasty lens by default**: Age, trajectory, years of control should be visible at a glance — not buried in a detail page
4. **Show confidence**: Display confidence indicators when model is less certain
5. **Make it personal**: Prominently show "Customized for your league" when settings applied

---

## 7. Development Phases

### Phase 1: Data Foundation + Marcel Baseline + Auction Values + Minimal API

**Goal:** A working API that returns Marcel projections, auction dollar values, and basic stats for all MLB players.

- Set up PostgreSQL via Docker Compose
- Implement data fetchers: FanGraphs stats (2015-present), Statcast aggregates (2019-present), player ID mapping
- Build data cleaning and database loading pipeline
- Run historical backfill via `scripts/seed_database.py`
- Implement Marcel baseline projections
- Implement feature engineering pipeline
- Implement auction valuation engine: projected stats → fantasy points → SGP → dollar values
- Implement surplus value calculation (projected value minus expected cost)
- Build FastAPI with `/players`, `/rankings`, and `/rankings/auction-values` endpoints (Marcel-based)
- Scaffold Next.js frontend: sidebar layout, player table (with auction $ columns), player detail (stats + auction value)
- Set up league settings with dynasty/auction configuration
- Connect frontend to API, verify end-to-end flow
- Write tests for fetchers, cleaning, valuation, API

**Deliverable:** Browse all MLB players, see 3-year stat history, Marcel projections, and auction dollar values with surplus. Dynasty/auction league settings configurable. No ML or AI scouting yet, but data infrastructure and valuation engine are solid.

### Phase 2: Core ML Models + AI Scouting Reports + Dynasty UI

**Goal:** All ML model outputs trained and served. LLM scouting reports generated. Frontend shows AI scores, scouting narratives, and dynasty/auction context.

**ML Models:**
- Train sleeper model (LightGBM + XGBoost ensemble, 2016-2023 data, validate on 2024)
- Train bust model (same ensemble approach)
- Train regression model (XGBoost + LightGBM regressors)
- Implement backtesting framework with walk-forward validation
- Implement Optuna hyperparameter tuning
- Implement consistency scoring (multi-year CV across sticky stats, weighted by stickiness tier)
- Implement improvement scoring (skills-stat trend slopes × r² × age multiplier)
- Implement composite AI Value Score with dynasty premium weighting
- Integrate SHAP for feature explanations
- Build unified inference pipeline

**AI Scouting Reports:**
- Set up Anthropic Python SDK integration (`llm/client.py`)
- Build context assembly layer: structured player data → prompt-ready document (`llm/prompts/formatters.py`)
- Design and iterate on scouting report prompt templates (`llm/prompts/scouting_report.py`)
- Implement report generation with all 4 report types (full, sleeper_spotlight, bust_warning, dynasty_outlook)
- Implement batch generation pipeline (~300 reports per cycle)
- Implement on-demand generation for uncached players
- Implement caching and staleness detection (`llm/generators/cache_manager.py`)
- Add `/players/{id}/scouting-report` API endpoint

**Dynasty & Auction Refinement:**
- Integrate model scores into auction valuation (regression-adjusted projections → updated dollar values)
- Implement dynasty value scoring with multi-year horizon
- Implement keep/cut horizon calculation
- Add `/rankings/dynasty` endpoint

**Frontend:**
- Build player detail page with AI scouting report as hero content
- Build AI assessment cards with auction $ and dynasty value
- Build sleepers page with scouting summaries and surplus values
- Build busts page with risk narratives and sell-high framing
- Build comparison page with auction/dynasty comparison rows
- Build settings page with dynasty/keeper/auction configuration
- Add radar charts, stat trend charts, value gauges, dynasty trajectory chart

**Deliverable:** The full AI value proposition. Users read narrative scouting reports, find sleepers, avoid busts, see auction values with surplus, and understand dynasty outlook — all personalized to their league settings.

### Phase 3: Advanced Models, Polish, Deployment

**Goal:** Career trajectory model, nightly automation, production deployment.

- Implement Temporal Fusion Transformer for multi-season career trajectory prediction
- Integrate trajectory predictions into dynasty value and AI Value Score
- Add trajectory visualization to player detail page (projected value curve with confidence bands)
- Implement APScheduler for nightly data refresh + weekly re-inference + batch scouting report regeneration
- Add roster/injury monitoring with push-to-projections updates (+ report staleness triggers)
- Implement API response caching
- Implement scouting report cost monitoring and throttling
- Dockerize full stack (multi-stage builds)
- Set up CI/CD with GitHub Actions
- Deploy to cloud provider
- Add daily AI insights digest
- Performance optimization (DB indexes, frontend bundle, LLM prompt optimization)
- Beta testing with dynasty league players

**Deliverable:** Production-deployed application with nightly updates, AI scouting reports, all model outputs, career trajectory projections, dynasty/auction optimization, and polished UI.
