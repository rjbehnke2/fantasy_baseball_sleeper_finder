# Fantasy Baseball Sleeper Finder — Implementation Plan

## Vision

A web application that uses ML models and LLM-powered analysis trained on baseball statistics and advanced analytics to generate AI-derived player evaluations for **dynasty auction** fantasy baseball leagues. The core differentiator is AI-powered insights: sleeper identification, bust detection, regression prediction, consistency scoring, composite value rankings, and **narrative scouting reports generated by an LLM** that synthesize all analytical signals into human-quality write-ups — the kind of analysis you'd get from a dedicated league analyst.

**Dynasty focus** means long-term value, age curves, prospect trajectories, and multi-year outlook matter as much or more than next-season projections. **Auction focus** means every player has a dollar value, and the key question is surplus value — the gap between what a player is worth and what they'll cost you.

---

## 1. Tech Stack

| Layer | Technology | Rationale |
|---|---|---|
| **Backend** | Python 3.11+ / FastAPI / Uvicorn | ML models are Python-native; FastAPI gives auto-docs, async, Pydantic validation |
| **Frontend** | Next.js (App Router) + shadcn/ui + Tailwind CSS + Recharts | Server-side rendering, production-quality components, built-in charting |
| **ML** | scikit-learn + XGBoost + LightGBM + SHAP | XGBoost/LightGBM excel on tabular baseball data; SHAP provides explainability |
| **AI/LLM** | Anthropic Python SDK (Claude API) | Powers narrative scouting reports — the primary AI differentiator |
| **Database** | PostgreSQL (SQLAlchemy 2.0 + Alembic) | Handles millions of Statcast rows, JSONB for flexible schemas, concurrent access |
| **Data** | pybaseball + MLB-StatsAPI | pybaseball aggregates FanGraphs/Savant/Lahman; MLB-StatsAPI for rosters/injuries |
| **Scheduling** | APScheduler | Nightly data refresh without the complexity of Celery |
| **Package Mgmt** | uv | Fast, reliable Python dependency management |
| **Infra** | Docker Compose (dev), GitHub Actions (CI/CD) | Single-command local stack, automated deploys |

---

## 2. Project Structure

```
fantasy_baseball_sleeper_finder/
├── README.md
├── PLAN.md
├── pyproject.toml
├── docker-compose.yml
├── .env.example
├── .gitignore
│
├── backend/
│   ├── alembic/                      # Database migrations
│   │   ├── versions/
│   │   ├── env.py
│   │   └── alembic.ini
│   │
│   ├── app/
│   │   ├── __init__.py
│   │   ├── main.py                   # FastAPI app factory, lifespan events
│   │   ├── config.py                 # Pydantic BaseSettings
│   │   ├── dependencies.py
│   │   │
│   │   ├── api/v1/
│   │   │   ├── router.py             # Aggregates all v1 routers
│   │   │   ├── players.py            # Player lookup, search, detail
│   │   │   ├── rankings.py           # AI rankings endpoints
│   │   │   ├── comparisons.py        # Player comparison endpoints
│   │   │   ├── insights.py           # Sleepers, busts, regression
│   │   │   └── league.py             # League settings customization
│   │   │
│   │   ├── models/                   # SQLAlchemy ORM models
│   │   │   ├── player.py
│   │   │   ├── batting_stats.py
│   │   │   ├── pitching_stats.py
│   │   │   ├── statcast.py
│   │   │   ├── projections.py
│   │   │   ├── scouting_report.py    # Cached LLM-generated reports
│   │   │   └── league_settings.py
│   │   │
│   │   ├── schemas/                  # Pydantic request/response schemas
│   │   │   ├── player.py
│   │   │   ├── rankings.py
│   │   │   ├── insights.py
│   │   │   ├── scouting_report.py
│   │   │   └── league.py
│   │   │
│   │   ├── services/                 # Business logic layer
│   │   │   ├── player_service.py
│   │   │   ├── ranking_service.py
│   │   │   ├── insight_service.py
│   │   │   ├── scouting_report_service.py  # LLM scouting report generation
│   │   │   └── auction_service.py          # Auction dollar values & surplus calc
│   │   │
│   │   └── db/
│   │       ├── session.py            # Async SQLAlchemy session factory
│   │       └── base.py               # Declarative base
│   │
│   ├── data_pipeline/
│   │   ├── fetchers/
│   │   │   ├── fangraphs_fetcher.py  # pybaseball batting_stats/pitching_stats
│   │   │   ├── statcast_fetcher.py   # pybaseball statcast functions
│   │   │   ├── roster_fetcher.py     # MLB-StatsAPI roster/injury data
│   │   │   └── player_id_mapper.py   # Cross-reference player IDs
│   │   │
│   │   ├── transformers/
│   │   │   ├── cleaning.py           # Data cleaning, null handling
│   │   │   ├── feature_engineering.py # Derived features (differentials, trends)
│   │   │   └── aggregations.py       # Pitch-level to season-level rollups
│   │   │
│   │   ├── loaders/
│   │   │   └── db_loader.py          # Write cleaned data to PostgreSQL
│   │   │
│   │   ├── orchestrator.py           # Pipeline scheduling logic
│   │   └── backfill.py               # One-time historical data load
│   │
│   ├── ml/
│   │   ├── features/
│   │   │   ├── feature_store.py      # Central feature definitions
│   │   │   ├── batter_features.py
│   │   │   └── pitcher_features.py
│   │   │
│   │   ├── models/
│   │   │   ├── marcel_baseline.py    # Marcel projection (baseline to beat)
│   │   │   ├── sleeper_model.py      # Sleeper detection
│   │   │   ├── bust_model.py         # Bust detection
│   │   │   ├── regression_model.py   # Regression direction prediction
│   │   │   ├── consistency_model.py  # Consistency/volatility scorer
│   │   │   ├── value_model.py        # Composite AI Value Score
│   │   │   └── trajectory_model.py   # TFT career trajectory (Phase 3)
│   │   │
│   │   ├── training/
│   │   │   ├── train_pipeline.py     # End-to-end training orchestration
│   │   │   ├── evaluation.py         # Backtesting, cross-validation
│   │   │   └── hyperparameter.py     # Optuna hyperparameter search
│   │   │
│   │   ├── inference/
│   │   │   ├── predictor.py          # Load models, generate predictions
│   │   │   └── explainer.py          # SHAP explanations
│   │   │
│   │   └── artifacts/                # Serialized models (.joblib, .xgb)
│   │       └── .gitkeep
│   │
│   ├── llm/
│   │   ├── __init__.py
│   │   ├── client.py                 # Anthropic SDK client wrapper
│   │   ├── prompts/
│   │   │   ├── scouting_report.py    # Prompt templates for scouting reports
│   │   │   ├── report_sections.py    # Sub-prompts: dynasty outlook, auction value, etc.
│   │   │   └── formatters.py         # Stat context formatters (structured → prompt-ready)
│   │   ├── generators/
│   │   │   ├── scouting_generator.py # Orchestrates full report generation
│   │   │   └── cache_manager.py      # Report caching / invalidation logic
│   │   └── tests/
│   │       └── test_scouting.py
│   │
│   └── tests/
│       ├── conftest.py
│       ├── test_api/
│       ├── test_pipeline/
│       └── test_ml/
│
├── frontend/
│   ├── package.json
│   ├── next.config.ts
│   ├── tailwind.config.ts
│   ├── tsconfig.json
│   │
│   └── src/
│       ├── app/
│       │   ├── layout.tsx            # Root layout with sidebar nav
│       │   ├── page.tsx              # Dashboard
│       │   ├── players/
│       │   │   ├── page.tsx          # Player rankings table
│       │   │   └── [playerId]/
│       │   │       └── page.tsx      # Player detail
│       │   ├── sleepers/page.tsx     # Sleeper picks
│       │   ├── busts/page.tsx        # Bust alerts
│       │   ├── compare/page.tsx      # Side-by-side comparison
│       │   └── settings/page.tsx     # League settings
│       │
│       ├── components/
│       │   ├── ui/                   # shadcn/ui components
│       │   ├── players/
│       │   │   ├── player-card.tsx
│       │   │   ├── player-table.tsx
│       │   │   ├── player-radar.tsx
│       │   │   └── scouting-report.tsx  # LLM scouting report display
│       │   ├── insights/
│       │   │   ├── sleeper-card.tsx
│       │   │   ├── bust-alert.tsx
│       │   │   └── regression-indicator.tsx
│       │   ├── auction/
│       │   │   ├── auction-value-badge.tsx  # Dollar value display
│       │   │   └── surplus-indicator.tsx    # Surplus value vs. cost
│       │   └── charts/
│       │       ├── stat-trend.tsx
│       │       ├── value-gauge.tsx
│       │       ├── consistency-heatmap.tsx
│       │       └── dynasty-trajectory.tsx   # Multi-year value projection
│       │
│       ├── lib/
│       │   ├── api.ts                # API client
│       │   ├── types.ts
│       │   └── utils.ts
│       │
│       └── hooks/
│           ├── use-players.ts
│           ├── use-rankings.ts
│           └── use-league-settings.ts
│
├── notebooks/
│   ├── 01_data_exploration.ipynb
│   ├── 02_feature_engineering.ipynb
│   ├── 03_model_prototyping.ipynb
│   └── 04_model_evaluation.ipynb
│
└── scripts/
    ├── seed_database.py
    ├── train_models.py
    └── generate_projections.py
```

---

## 3. Data Pipeline

### 3.1 Data Sources

| Source | Library | Data Type | Historical Depth |
|---|---|---|---|
| FanGraphs | `pybaseball.batting_stats()` / `pitching_stats()` | Season-level advanced stats (wOBA, xwOBA, wRC+, SIERA, FIP, Barrel%, etc.) | 2015-present |
| Baseball Savant | `pybaseball.statcast()` | Pitch-level Statcast (EV, LA, spin rate, etc.) | 2019-present |
| Lahman Database | `pybaseball` Lahman module | Historical season stats | 1871-present |
| MLB Stats API | `MLB-StatsAPI` | Rosters, injuries, schedules | Current |

### 3.2 Fetching Strategy

**Historical Backfill** (one-time, via `scripts/seed_database.py`):
- FanGraphs batting/pitching stats: 2015-present (single call per stat type)
- Statcast aggregates: 2019-present, fetched in 7-day chunks to stay under Baseball Savant's 30K row limit
- Always enable `pybaseball.cache.enable()` before fetching

**Nightly Incremental Updates** (via APScheduler, 5:00 AM ET):
- Yesterday's Statcast data
- Re-aggregate current-season per-player Statcast summaries
- Roster changes and injury updates via MLB-StatsAPI
- Monthly full FanGraphs stats refresh

### 3.3 Player ID Mapping

Critical integration challenge. pybaseball uses MLBAM IDs, FanGraphs has its own IDs, Baseball Reference uses another. The `player_id_mapper.py` module uses `pybaseball.playerid_reverse_lookup()` to build a canonical player table with all three ID systems for reliable cross-source joins.

### 3.4 Database Schema

**`players`** — canonical player record
- `id` (PK), `mlbam_id`, `fangraphs_id`, `bbref_id`, `full_name`, `position`, `team`, `birth_date`, `mlb_debut_date`, `status`, `prospect_rank` (historical top-100 ranking, if any), `mlb_service_time`

**`batting_seasons`** — one row per player per season
- `player_id` (FK), `season`, `pa`, `ab`, `h`, `hr`, `rbi`, `sb`, `avg`, `obp`, `slg`, `woba`, `xwoba`, `wrc_plus`, `barrel_pct`, `hard_hit_pct`, `sprint_speed`, `babip`, `k_pct`, `bb_pct`, `war`, `adp`

**`pitching_seasons`** — one row per player per season
- `player_id` (FK), `season`, `ip`, `era`, `whip`, `fip`, `xfip`, `siera`, `k_pct`, `bb_pct`, `k_bb_pct`, `csw_pct`, `swstr_pct`, `barrel_pct_against`, `hard_hit_pct_against`, `stuff_plus`, `war`, `babip`, `lob_pct`, `hr_fb_pct`, `adp`

**`statcast_aggregates`** — per-player-per-season Statcast summaries
- `player_id` (FK), `season`, `avg_exit_velocity`, `max_exit_velocity`, `avg_launch_angle`, `barrel_pct`, `sweet_spot_pct`, `avg_spin_rate`, `xba`, `xslg`, `xwoba`, `xera`

**`monthly_splits`** — per-player-per-month (for consistency scoring)
- `player_id` (FK), `season`, `month`, key rate stats

**`projections`** — model outputs
- `player_id` (FK), `run_date`, `model_version`, `sleeper_score`, `bust_score`, `regression_direction`, `regression_magnitude`, `consistency_score`, `ai_value_score`, `confidence`, `shap_explanations` (JSONB), `auction_value` (projected dollar value), `dynasty_value` (long-term value score 0-100), `surplus_value` (auction_value minus expected cost)

**`scouting_reports`** — cached LLM-generated reports
- `id` (PK), `player_id` (FK), `report_type` (full/sleeper_spotlight/bust_warning/dynasty_outlook), `content` (TEXT — the full generated report), `model_scores_snapshot` (JSONB — scores at time of generation), `llm_model_version`, `generated_at`, `stale` (boolean — flagged when underlying data changes significantly)

**`league_settings`** — user-customizable league configs
- `id`, `name`, `scoring_type` (roto/h2h_categories/h2h_points), `league_format` (redraft/keeper/dynasty), `roster_slots` (JSONB), `stat_categories` (JSONB), `auction_budget` (default 260), `roster_size`, `keeper_rules` (JSONB — max keepers, cost inflation, etc.)

### 3.5 Feature Engineering

This is the intellectual core of the pipeline — the quality of features determines the quality of all ML models.

**Differential Features (actual vs. expected):**
- `woba_minus_xwoba`: positive = overperforming (bust signal), negative = underperforming (sleeper signal)
- `ba_minus_xba`, `era_minus_xera`: same principle
- `babip_minus_league_avg`: high delta suggests regression

**Trend Features (year-over-year):**
- `barrel_pct_yoy_delta`, `k_pct_yoy_delta`, `bb_pct_yoy_delta`, `csw_pct_yoy_delta`
- 2-year and 3-year trend slopes via linear regression on seasonal values

**Age Curve Features:**
- `age`, `years_from_peak` (peak ~27 hitters, ~26 pitchers)
- `age_bucket`: pre-peak / peak / early-decline / late-decline
- `post_hype_flag`: age 26-29, former top prospect, MLB underperformer

**Consistency Features (from monthly splits):**
- `woba_cv`: coefficient of variation of monthly wOBA
- `woba_iqr`: interquartile range
- `bad_month_ratio`: fraction of months below league average
- `hot_streak_magnitude`: max monthly wOBA minus season wOBA

**Context Features:**
- `team_park_factor`, `lineup_position_avg`, `playing_time_trend`

**Marcel Baseline Features:**
- Weighted 3-year average (5/4/3 weighting)
- Regression to mean (1200 PA batters / 134 outs pitchers of league-average blended in)
- Age adjustment: +/- 0.006 per year from peak

---

## 4. ML Models (Core Differentiator)

### 4.0 Marcel Baseline — The Bar to Clear

Every ML model must demonstrably outperform the Marcel system. Marcel is implemented first and its projections also serve as input features for downstream models.

**Formula:** `projected_stat = (5 * year_N + 4 * year_N-1 + 3 * year_N-2) / 12`, regressed toward league mean proportional to playing time, age-adjusted.

### 4.1 Sleeper Finder Model

**Objective:** Identify players whose underlying quality (Statcast, expected stats) significantly exceeds their surface stats or auction cost. In dynasty context, also flags young players whose long-term trajectory is underpriced.

**Training Target:** Binary classification. A "sleeper" = player whose auction cost was in the bottom 60% of rostered players but who finished the season in the top 40% by fantasy value.

**Key Features (expected importance order):**
1. `xwoba_minus_woba` (negative = quality exceeds results)
2. `barrel_pct` + `barrel_pct_yoy_delta`
3. `hard_hit_pct` + `hard_hit_pct_yoy_delta`
4. `k_pct_yoy_delta` (declining K rate)
5. `csw_pct_yoy_delta` (pitchers: improving stuff)
6. `age_bucket` (pre-peak more likely to break out)
7. `playing_time_trend` (increasing = team trust)
8. `post_hype_flag`
9. Marcel delta (projected vs. actual)
10. `auction_cost_pct` (cheap + good underlying = sleeper)
11. `years_of_control` (dynasty: more team control = more long-term value)

**Architecture:** LightGBM + XGBoost ensemble with class-weight balancing (sleepers are ~5-10% of pool). Calibrated probabilities via `CalibratedClassifierCV`. Hyperparameter tuning with Optuna, 5-fold time-series CV.

**Output:** `sleeper_score` (0-100) + SHAP top-3 feature explanations per player.

### 4.2 Bust Detector Model

**Objective:** Flag players whose surface stats are propped up by unsustainable luck, making them likely to disappoint relative to their auction cost. In dynasty, also flags aging players whose decline is being underpriced.

**Training Target:** Binary classification. A "bust" = player whose auction cost was in the top 30% but who finished outside the top 60% by fantasy value (or 60+ days on IL).

**Key Features:**
1. `woba_minus_xwoba` (positive = stats exceed quality)
2. `babip_minus_league_avg` (high BABIP regresses)
3. `hr_fb_pct` vs. league average (unsustainable HR/FB)
4. `lob_pct` for pitchers (high LOB% regresses down)
5. `age_bucket` (late-decline = higher bust risk)
6. `injury_history_score` (weighted IL stints)
7. `era_minus_fip` for pitchers
8. `consistency_score` (volatile = higher bust risk)
9. `playing_time_trend` (declining = team losing faith)
10. `age_times_cost` (dynasty: expensive + old = highest bust risk)

**Architecture:** Same LightGBM + XGBoost ensemble. Same tuning framework.

**Output:** `bust_score` (0-100) + SHAP top-3 explanations.

### 4.3 Regression Direction Model

**Objective:** Predict whether a player will improve or decline, and by how much.

**Training Target:** Regression task. Target = `next_season_woba - current_season_woba` (batters) or `current_season_fip - next_season_fip` (pitchers, inverted for unified "improvement" metric).

**Key Features:** All differential features + Marcel deltas + YoY trends + age curve.

**Architecture:** XGBoost Regressor + LightGBM Regressor ensemble. Evaluated with MAE and directional accuracy.

**Output:** `regression_direction` (signed float), `regression_confidence` (from quantile regression prediction intervals).

### 4.4 Consistency Score

**Not an ML model** — a statistical calculation from monthly splits data.

**Formula:**
```
consistency_score = 100 - normalize(
    0.4 * coefficient_of_variation +
    0.3 * iqr_scaled +
    0.2 * bad_month_ratio +
    0.1 * max_drawdown_scaled
)
```

Multi-year smoothing: current season 60%, prior 30%, two seasons ago 10%.

**Output:** `consistency_score` (0-100) + monthly performance array for sparkline visualization.

### 4.5 AI Value Score (Composite)

**Objective:** Single 0-100 number combining all model outputs with contextual factors, weighted for dynasty auction leagues.

**Formula:**
```
ai_value_score = (
    w1 * projected_fantasy_value +      # Marcel + regression adjustment
    w2 * sleeper_upside +               # sleeper_score * (1 - current_value_pct)
    w3 * (100 - bust_risk) +            # Inverse bust score
    w4 * consistency_score +
    w5 * age_curve_factor +             # Bonus pre-peak, penalty late-decline
    w6 * opportunity_score +            # Playing time / role security
    w7 * dynasty_premium               # Long-term value (see below)
)
```

**Dynasty Premium Calculation:**
The `dynasty_premium` adjusts the value score to reflect multi-year outlook, which is the defining feature of dynasty leagues:
```
dynasty_premium = (
    years_of_control_bonus +            # More years = more value
    age_trajectory_score +              # Pre-peak players get a premium
    prospect_pedigree_bonus +           # Former top prospects still developing
    positional_scarcity_factor          # Dynasty-thin positions worth more long-term
)
```
- A 24-year-old with 5 years of control and improving Statcast metrics gets a significant dynasty premium even if his current stats are modest
- A 33-year-old with elite current stats but declining velocity trends gets a dynasty penalty
- Post-hype sleepers (age 26-29, former top-100 prospect, hasn't broken out yet) get a targeted bonus — these are classic dynasty buy-low windows

Weights `w1-w7` calibrated via linear regression on historical seasons, with dynasty weights trained on multi-year value windows (3-year cumulative fantasy value, not just next season).

**League Customization:** `projected_fantasy_value` changes based on user's league settings (categories vs. points, roster composition, keeper/dynasty rules). Rankings adjust accordingly.

**Output:** `ai_value_score` (0-100) + component breakdown for the UI explainer.

### 4.6 AI Scouting Reports (LLM-Powered)

**Objective:** Generate narrative scouting reports that synthesize all analytical signals — model scores, Statcast data, trends, age context, dynasty outlook, auction implications — into human-quality write-ups. This is the primary AI differentiator of the application.

**Why this matters:** A sleeper score of 78 is a number. A scouting report that says *"Vazquez quietly overhauled his swing last spring, and the Statcast data backs it up — his barrel rate jumped from 6% to 11%, exit velocity climbed 3 mph, yet his BABIP sat at .260 all year. He was one of the unluckiest hitters in baseball. At $3 in your auction, he's a potential league-winner with 5 years of team control remaining."* — that's actionable intelligence.

**Architecture:**

The scouting report system has three layers:

**Layer 1: Context Assembly (`formatters.py`)**
For each player, assemble a structured context document containing:
- Biographical: name, age, team, position, years of control, prospect history
- Current season stats: all key metrics with league-average comparisons and percentile ranks
- 3-year trends: each stat's trajectory with direction arrows
- Model scores: sleeper_score, bust_score, regression_direction, consistency_score, ai_value_score — with the top SHAP features for each
- Differentials: xwOBA vs. wOBA, xBA vs. BA, xERA vs. ERA — the "luck gap"
- Dynasty context: age curve position, years until free agency, comparable players at this age
- Auction context: projected dollar value, expected cost, surplus value

This structured data is formatted into a prompt-ready document that provides the LLM with complete, grounded context. The LLM never invents stats — it synthesizes and narrates what the models found.

**Layer 2: Prompt Templates (`scouting_report.py`, `report_sections.py`)**
A system prompt establishes the LLM's role as a fantasy baseball analyst with dynasty/auction expertise. The prompt includes:
- Explicit instruction to only reference stats and scores provided in the context (no hallucination)
- Tone guidance: authoritative but accessible, like a trusted league-mate who's done the homework
- Section structure for the report (see below)
- Dynasty-specific framing: always consider long-term value, age trajectory, and cost basis

**Report Sections:**
1. **Headline Assessment** (1-2 sentences): The takeaway. "Buy" / "Sell" / "Hold" with conviction level.
2. **The Case For** (1 paragraph): What the underlying data says in the player's favor — Statcast quality, improving trends, favorable age. Written as a narrative, not a stat dump.
3. **The Case Against** (1 paragraph): Risk factors — regression signals, injury history, declining trends, age concerns.
4. **Dynasty Outlook** (1 paragraph): Multi-year trajectory. Where is this player on his career arc? What's the 3-year projection? Is he a buy-and-hold cornerstone or a sell-high candidate?
5. **Auction Verdict** (1-2 sentences): Specific dollar value recommendation. "Worth up to $22 in a 12-team dynasty auction — $5 more than his expected cost, making him one of the best surplus values on the board."

**Layer 3: Generation & Caching (`scouting_generator.py`, `cache_manager.py`)**

- **Batch generation:** After each model inference run, generate reports for the top ~300 relevant players (top 250 by value + top 50 sleepers/busts). Reports are generated in batch via async Claude API calls. This avoids per-request latency — users get instant access to pre-generated reports.
- **On-demand generation:** If a user views a player without a cached report, generate one on-the-fly (takes ~3-5 seconds). Show a loading state in the UI.
- **Cache invalidation:** Reports are marked `stale` when any of these triggers occur:
  - Model scores change by more than 10 points
  - Player changes teams (trade/free agency)
  - Player goes on/off the IL
  - New season data significantly shifts their stats
  - A new model version is deployed
- **Staleness regeneration:** Stale reports are regenerated in the next nightly batch. Until regenerated, the old report is still served (better than nothing) with a "Report may be outdated" indicator.
- **Cost control:** Claude API calls are the main operational cost. Batch generation of ~300 reports per cycle is manageable. On-demand generation is throttled (max 10 concurrent requests). Reports are cached aggressively — most users will hit the cache.

**Report Types:**
| Type | When Generated | Content Focus |
|---|---|---|
| `full` | Batch (top 300 players) | Complete 5-section report |
| `sleeper_spotlight` | Batch (top 50 by sleeper_score) | Emphasizes undervaluation case + dynasty buy-low window |
| `bust_warning` | Batch (top 50 by bust_score) | Emphasizes risk factors + sell-high case |
| `dynasty_outlook` | Batch (top prospects + young players) | Emphasizes career trajectory + long-term value |

**Quality Guardrails:**
- The LLM is never asked to generate stats — only to narrate stats provided in the context
- Each report includes a `model_scores_snapshot` stored alongside it, so the UI can show if the report's basis has shifted
- Reports include a "Generated on [date] using [model version]" footer for transparency

### 4.7 Auction Valuation Engine

**Objective:** Convert projected fantasy production into dollar values for auction drafts, and calculate surplus value (the gap between what a player is worth and what they'll cost).

**Methodology:**

**Step 1: Stat Projections → Fantasy Points**
Convert each player's projected stats (from Marcel + regression adjustment) into fantasy points or category contributions based on the user's league settings.

**Step 2: Fantasy Points → Dollar Values (Standings Gain Points method)**
The standard auction valuation approach:
1. For each stat category, calculate how much one additional unit of that stat would improve your standings (the "SGP" — standings gain point)
2. A player's total value = sum of SGP contributions across all categories
3. Scale to the league's auction budget: `dollar_value = (player_sgp / total_pool_sgp) * total_league_dollars_on_hitters_or_pitchers`

For points leagues, the conversion is simpler: projected points → dollar value proportional to budget.

**Step 3: Surplus Value**
```
surplus_value = projected_dollar_value - expected_auction_cost
```
`expected_auction_cost` is derived from ADP-to-dollar mappings, historical auction results, or user-provided keeper costs.

**Dynasty Adjustments:**
- **Multi-year dollar value:** In dynasty, a player's value isn't just their next-season projection — it's the sum of projected value over their remaining years of control, discounted by uncertainty. A $20/year player with 5 years of control is worth more than a $25/year player with 1 year left.
- **Keeper cost inflation:** If the league inflates keeper costs by $5/year, the model accounts for when a player's keeper cost will exceed their projected value (the "keep/cut" inflection point).
- **Aging discount rate:** Future seasons are discounted more heavily for older players (higher probability of decline/injury).

**Output:** `auction_value` (dollar amount), `dynasty_value` (0-100 long-term score), `surplus_value` (dollar amount), `keep_cut_horizon` (years until keeper cost exceeds value).

---

## 5. API Design

### Base URL: `/api/v1`

### Players
| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/players` | Paginated search/list with filters (position, team, sort_by any score, sort_by auction_value/dynasty_value/surplus_value) |
| `GET` | `/players/{player_id}` | Full detail: bio, 3-year stats, all model scores, SHAP explanations, monthly splits, auction value, dynasty outlook |
| `GET` | `/players/{player_id}/stats` | Historical stats by season and stat type |
| `GET` | `/players/{player_id}/scouting-report` | LLM-generated scouting report (returns cached if available, generates on-demand if not; includes report_type param: full/sleeper_spotlight/bust_warning/dynasty_outlook) |

### Rankings
| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/rankings` | AI-powered rankings with value breakdown per player |
| `GET` | `/rankings/sleepers` | Top sleeper candidates with reasons |
| `GET` | `/rankings/busts` | Top bust risks with reasons |
| `GET` | `/rankings/regression` | Regression candidates by direction |
| `GET` | `/rankings/dynasty` | Dynasty-specific rankings (weighted toward long-term value, age, trajectory) |
| `GET` | `/rankings/auction-values` | All players sorted by projected auction dollar value, with surplus values |

### Comparisons
| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/compare?player_ids=1,2,3` | Side-by-side comparison with percentile-coded stats, auction values, dynasty outlook |

### League Settings
| Method | Endpoint | Description |
|---|---|---|
| `POST` | `/league-settings` | Create league config (scoring type, categories, roster, league_format: dynasty/keeper/redraft, auction_budget, keeper_rules) |
| `GET` | `/league-settings/{id}` | Retrieve league config |

### Insights & Metadata
| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/insights/daily` | Daily AI digest: risers, fallers, injury impacts |
| `GET` | `/model/info` | Model version, last-trained date, backtest accuracy |

---

## 6. Frontend Design

### Pages

**Dashboard (`/`)** — Landing page with:
- "Today's Top Sleepers" card (top 5 with one-line AI scouting summary each)
- "Bust Alerts" card (top 5 warnings with one-line risk summary)
- "Best Auction Values" card (top 5 by surplus value, showing projected $ vs. expected cost)
- "Dynasty Risers" card (players whose dynasty value increased most)
- Quick-search bar, model freshness indicator

**Player Rankings (`/players`)** — Full-width sortable/filterable table (Tanstack Table):
- Columns: Rank, Name, Team, Pos, Age, AI Value Score, Auction $, Surplus $, Dynasty Value, Sleeper Score, Bust Score, Consistency, key stats
- Sidebar filters: position, team, age range, min PA/IP
- Toggle: All / Batters / Pitchers
- View presets: "Dynasty Rankings" / "Auction Values" / "Sleeper Board" / "Bust Watch"
- League settings toggle for personalized rankings

**Player Detail (`/players/[playerId]`)** — Most information-dense page:
- **AI Scouting Report** (prominent, top of page): The full LLM-generated narrative — headline assessment, case for, case against, dynasty outlook, auction verdict. Displayed in a styled card with a "Generated by AI" badge and timestamp. If not yet generated, show loading state with "Generating scouting report..."
- AI Assessment Card: value gauge (0-100, color gradient), sleeper/bust/consistency badges
- **Auction & Dynasty Card**: projected dollar value (large), surplus value, dynasty value score, keep/cut horizon ("Worth keeping for 3 more years at current inflation")
- Stat Trends: 3-year line charts (wOBA, xwOBA, Barrel%, K%)
- Dynasty Trajectory Chart: projected multi-year value curve with confidence band
- Monthly Splits Heatmap
- Radar Chart: percentile ranks across key metrics (Power, Contact, Speed, Discipline)
- "Compare with..." shortcut

**Sleepers (`/sleepers`)** — Card layout:
- Sleeper score (large), projected auction $ and surplus value
- AI scouting summary (2-3 sentence excerpt from the sleeper_spotlight report)
- Mini sparkline: xwOBA vs. wOBA over 3 seasons
- Sortable, position-filterable

**Busts (`/busts`)** — Same card layout, warning color scheme (amber/red):
- Bust score, current auction cost, projected value loss
- AI scouting summary (excerpt from bust_warning report)
- Key risk factors as visual indicators

**Compare (`/compare`)** — Select 2-5 players:
- Side-by-side stat table, cells color-coded by percentile
- Auction value comparison row ($ values, surplus)
- Dynasty value comparison with trajectory overlay
- Overlaid trend line charts
- Radar chart overlay

**Settings (`/settings`)** — League configuration form:
- League format: dynasty / keeper / redraft
- Scoring type (roto/H2H categories/H2H points)
- Stat categories (checkboxes)
- Roster slots, points-per-stat values
- Auction budget (default $260)
- Keeper/dynasty rules: max keepers, cost inflation rate, contract lengths

### Design Principles
1. **Lead with the scouting report**: The AI narrative is the hero content — it's what makes this app different from every stats dashboard
2. **Dollar signs everywhere**: In an auction league, every player has a price. Show auction $ and surplus $ on every card, every table row, every comparison
3. **Dynasty lens by default**: Age, trajectory, years of control should be visible at a glance — not buried in a detail page
4. **Show confidence**: Display confidence indicators when model is less certain
5. **Make it personal**: Prominently show "Customized for your league" when settings applied

---

## 7. Development Phases

### Phase 1: Data Foundation + Marcel Baseline + Auction Values + Minimal API

**Goal:** A working API that returns Marcel projections, auction dollar values, and basic stats for all MLB players.

- Set up PostgreSQL via Docker Compose
- Implement data fetchers: FanGraphs stats (2015-present), Statcast aggregates (2019-present), player ID mapping
- Build data cleaning and database loading pipeline
- Run historical backfill via `scripts/seed_database.py`
- Implement Marcel baseline projections
- Implement feature engineering pipeline
- Implement auction valuation engine: projected stats → fantasy points → SGP → dollar values
- Implement surplus value calculation (projected value minus expected cost)
- Build FastAPI with `/players`, `/rankings`, and `/rankings/auction-values` endpoints (Marcel-based)
- Scaffold Next.js frontend: sidebar layout, player table (with auction $ columns), player detail (stats + auction value)
- Set up league settings with dynasty/auction configuration
- Connect frontend to API, verify end-to-end flow
- Write tests for fetchers, cleaning, valuation, API

**Deliverable:** Browse all MLB players, see 3-year stat history, Marcel projections, and auction dollar values with surplus. Dynasty/auction league settings configurable. No ML or AI scouting yet, but data infrastructure and valuation engine are solid.

### Phase 2: Core ML Models + AI Scouting Reports + Dynasty UI

**Goal:** All ML model outputs trained and served. LLM scouting reports generated. Frontend shows AI scores, scouting narratives, and dynasty/auction context.

**ML Models:**
- Train sleeper model (LightGBM + XGBoost ensemble, 2016-2023 data, validate on 2024)
- Train bust model (same ensemble approach)
- Train regression model (XGBoost + LightGBM regressors)
- Implement backtesting framework with walk-forward validation
- Implement Optuna hyperparameter tuning
- Implement consistency scoring from monthly splits
- Implement composite AI Value Score with dynasty premium weighting
- Integrate SHAP for feature explanations
- Build unified inference pipeline

**AI Scouting Reports:**
- Set up Anthropic Python SDK integration (`llm/client.py`)
- Build context assembly layer: structured player data → prompt-ready document (`llm/prompts/formatters.py`)
- Design and iterate on scouting report prompt templates (`llm/prompts/scouting_report.py`)
- Implement report generation with all 4 report types (full, sleeper_spotlight, bust_warning, dynasty_outlook)
- Implement batch generation pipeline (~300 reports per cycle)
- Implement on-demand generation for uncached players
- Implement caching and staleness detection (`llm/generators/cache_manager.py`)
- Add `/players/{id}/scouting-report` API endpoint

**Dynasty & Auction Refinement:**
- Integrate model scores into auction valuation (regression-adjusted projections → updated dollar values)
- Implement dynasty value scoring with multi-year horizon
- Implement keep/cut horizon calculation
- Add `/rankings/dynasty` endpoint

**Frontend:**
- Build player detail page with AI scouting report as hero content
- Build AI assessment cards with auction $ and dynasty value
- Build sleepers page with scouting summaries and surplus values
- Build busts page with risk narratives and sell-high framing
- Build comparison page with auction/dynasty comparison rows
- Build settings page with dynasty/keeper/auction configuration
- Add radar charts, stat trend charts, value gauges, dynasty trajectory chart

**Deliverable:** The full AI value proposition. Users read narrative scouting reports, find sleepers, avoid busts, see auction values with surplus, and understand dynasty outlook — all personalized to their league settings.

### Phase 3: Advanced Models, Polish, Deployment

**Goal:** Career trajectory model, nightly automation, production deployment.

- Implement Temporal Fusion Transformer for multi-season career trajectory prediction
- Integrate trajectory predictions into dynasty value and AI Value Score
- Add trajectory visualization to player detail page (projected value curve with confidence bands)
- Implement APScheduler for nightly data refresh + weekly re-inference + batch scouting report regeneration
- Add roster/injury monitoring with push-to-projections updates (+ report staleness triggers)
- Implement API response caching
- Implement scouting report cost monitoring and throttling
- Dockerize full stack (multi-stage builds)
- Set up CI/CD with GitHub Actions
- Deploy to cloud provider
- Add daily AI insights digest
- Performance optimization (DB indexes, frontend bundle, LLM prompt optimization)
- Beta testing with dynasty league players

**Deliverable:** Production-deployed application with nightly updates, AI scouting reports, all model outputs, career trajectory projections, dynasty/auction optimization, and polished UI.
